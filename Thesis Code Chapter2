################################################
#############GARCH(1,1) estimation #############
################################################

#case 1
#gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
#true_par=c(w=0.04^2,c=0.254^2,d=0.941^2)
#> true_par
#w        c        d 
#0.001600 0.064516 0.885481 

#case2
#gar1=unigarch(totaltime=1200,burnin=200,w=0.03^2,c=0.332^2,d=0.864^2)
#true_par=c(w=0.03^2,c=0.332^2,d=0.864^2)
#> true_par
#w        c        d 
#0.000900 0.110224 0.746496 


rm(list=ls())
#install.packages("MASS")
#install.packages("grDevices")
library(MASS)
library(metRology)
unigarch=function(w,c,d,totaltime,burnin)
{
  eps=sig=0
  sig0=w/(1-c-d)
  z0=sig0^(0.5) * rnorm(1)
  eps0=z0*sig0^(0.5)
  sig[1]=w+c*eps0^2+d*sig0
  eps[1]=sig[1]^(0.5)*rnorm(1)
  for(i in 2:totaltime)  # Generate GARCH(1,1) process
  {
    sig[i]=w+c*eps[i-1]^2+d*sig[i-1]
    eps[i]=sig[i]^(0.5)*rnorm(1)
  }
  sigdata=sig
  epsdata=eps
  gar=cbind(sigdata,epsdata)
  output=gar[((burnin+1):totaltime),]
}






garch1=gar1
plot.ts(garch1)

plot(density(garch1[,1])) #sigma

plot(density(garch1[,2])) #data
qqnorm(garch1[,2])  #data normal distribution check
qqline(garch1[,2], col = "red")



#########update
garch_likelihood_constrained <- function(theta, returns) {
  omega <- theta[1]
  alpha <- theta[2]
  beta <- theta[3]
  # Check if parameters are within acceptable range
  if (omega > 0 || alpha > 0 || beta > 0 || 0< alpha + beta|| alpha + beta < 1) {
    T <- length(returns)
    sigma2 <- numeric(T)
    sigma2[1] <- var(returns)
    for (t in 2:T) {
      sigma2[t] <- omega + alpha * returns[t-1]^2 + beta * sigma2[t-1]
      if (sigma2[t] <= 0) {
        return(.Machine$double.xmax)
      }
    }
    log_likelihood <- -0.5 * (T * log(2 * pi) + sum(log(sigma2)) + sum(returns^2 / sigma2))
  }
  return(-log_likelihood) # Negative because 'optim' minimizes
}


garch_likelihood_constrained(theta=c(0.01, 0.1, 0.1),returns=garch1[,2])
log_likelihood=381.0842

garch_likelihood_constrained(theta=c(0.01, 0.1, 0.9),returns=garch1[,2])
log_likelihood=5.267867
garch_likelihood_constrained(theta=c(0.001, 0.06 ,0.88),returns=garch1[,2])


# Number of parameters in the model (omega, alpha, beta for GARCH(1,1))
p <- 3 
# Number of observations
n <- length(garch1[,2])
# Calculate AIC
aic <- -2 * log_likelihood + 2 * p
# Calculate BIC
bic <- -2 * log_likelihood + log(n) * p



# 进行GARCH(1,1)模型的参数估计
initial_guess <- c(0.001, 0.06 ,0.88)  # 初始参数猜测值(初始值很重要)
lower_bound <- c(1e-6, 1e-4, 1e-4)      # 参数下限
upper_bound <- c(1, 1-1e-4, 1-1e-4)   # 参数上限，确保 alpha + beta < 1
optim_result1 <- optim(initial_guess,garch_likelihood_constrained, returns=garch1[,2], 
                       method = "L-BFGS-B", lower = lower_bound, upper = upper_bound,
                       hessian=TRUE)
estimated_params=optim_result1$par
estimated_params
#case
#[1] 0.003968071 0.085097497 0.791463493
#case2
#[1] 0.004703353 0.127247069 0.126339038

#case 3
#[1] 0.008604938 0.085766343 0.085769991



initial_guess <- c(0.1, 0.01, 0.01)  # 初始参数猜测值(初始值很重要)
lower_bound <- c(1e-6, 1e-4, 1e-4)      # 参数下限
upper_bound <- c(1, 1-1e-4, 1-1e-4)   # 参数上限，确保 alpha + beta < 1
optim_result1 <- optim(initial_guess,garch_likelihood_constrained, returns=garch1[,2], 
                       method = "L-BFGS-B", lower = lower_bound, upper = upper_bound,
                       hessian=TRUE)
estimated_params=optim_result1$par
estimated_params

#case1
#[1] 0.004630044 0.092142727 0.766535095
#case2
#[1] 0.0062304212 0.0007174053 0.0007002197


######Function multiStart (better result)
#install.packages("BB")
library(BB)
pmat <- matrix(runif(3,0,1), 1, 3)  # 5 starting values each of length 3 
lower_bound <- c(1e-6, 1e-4, 1e-4)      # 参数下限
upper_bound <- c(1, 1-1e-4, 1-1e-4)   # 参数上限，确保 alpha + beta < 1
ans1 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                   lower = lower_bound, upper = upper_bound,
                   returns=garch1[,2],action="optimize")
ans1$par
estimated_params1=colMeans(ans1$par)
estimated_params1
#case 1
#[1] 0.002009957 0.072449240 0.866441530

#> true_par


#case2
#[1] 0.001201921 0.131406865 0.674716149


#check (not good)
library(rugarch)
r.garch <- ugarchspec(mean.model = list(armaOrder = c(0,0),
                                        include.mean = FALSE),variance.model = list(garchOrder = c(1, 1)))  # Fit garch(1,1) 
fit1 = ugarchfit(data = garch1[,2], spec = r.garch)    
fit1@fit$coef


garfit1=unigarch(totaltime=1200,burnin=200,
                 w=0.001800913,c=0.045903189,d=0.895352650)


plot.ts(fit1@fit$residuals)

acf(garch1[,2])
pacf(garch1[,2])
Box.test(garch1[,2], type = "Ljung-Box")

plot.ts(garch1[,2] - garfit1[,2])
plot.ts(garch1[,1] - garfit1[,1])

fit=ans1$par
garfit1=unigarch(totaltime=1200,burnin=200,w=0.001182586,c=0.06098994,d=0.8973598)



mse <- mean((garfit1[,2] - garch1[,2])^2)
# Calculate RMSE
rmse <- sqrt(mse)
# Calculate MAE
mae <- mean(abs(garfit1[,2] - garch1[,2]))


# Comparing statistical properties
# (Assuming 'simulated_data' and 'actual_data' are available)
actual_data=garch1[,2]
simulated_data=garfit1[,2]

actual_data=garch1[,1]
simulated_data=garfit1[,1]# Extracting the simulated sigma (volatility)


compare_stats <- function(simulated_data, actual_data) {
    comparison <- data.frame(
      Metric = c("Mean", "Variance", "Skewness", "Kurtosis"),
      Actual = c(mean(actual_data), var(actual_data), 
                 skewness(actual_data), kurtosis(actual_data)),
      Simulated = c(mean(simulated_data), var(simulated_data), 
                    skewness(simulated_data), kurtosis(simulated_data))
    )
    return(comparison)
  }
stats_comparison <- compare_stats(simulated_data, actual_data)
print(stats_comparison)


# Residuals analysis
residuals =garfit1[,2] - garch1[,2]
# ACF PACF plot of residuals to check for autocorrelation
acf(residuals, main="ACF of Residuals")
pacf(residuals, main="PACF of Residuals")

# Perform Ljung-Box test
Box.test(residuals, type = "Ljung-Box")





actual_volatility=garch1[,1]
estimated_volatility=garfit1[,1]
# Calculate statistical measures
mse <- mean((actual_volatility - estimated_volatility)^2)
#0.0001514126
mae <- mean(abs(actual_volatility - estimated_volatility))
#0.008960598
# Create a data frame for plotting
comparison_df <- data.frame(time = index(actual_volatility),
                            Actual = actual_volatility,
                            Estimated = estimated_volatility)

# Time series plot
ggplot(comparison_df, aes(x = time)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Estimated, color = "Estimated")) +
  labs(title = "Actual vs Estimated Volatility",
       color = "Legend") +
  theme_minimal()

plot.ts(actual_volatility - estimated_volatility)
plot.ts(actual_volatility - estimated_volatility,
        main = "Delta h_t between simulated vs. fitted", ylab = "Difference")

summary(actual_volatility - estimated_volatility)

var(actual_volatility - estimated_volatility)

skewness(actual_volatility - estimated_volatility)
kurtosis(actual_volatility - estimated_volatility)











#case 1
#0.002009794 0.072434284 0.866459763 

#case2
#> fit1@fit$coef
#omega      alpha1       beta1 
#0.001187264 0.130904389 0.677656260 

#case4
#7.600748e-05 1.698201e-01 7.388840e-01 


#sampling distribution
repe=500
time=1000
estimated_par=matrix(0,repe,3)
#xx2=matrix(0,time,2*repe)
#install.packages("matrixcalc")
library(matrixcalc)
#sigma=matrix(0,time,repe)
library(MASS)
library(metRology)
m <- 1
repeat 
{
  #case1
  gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
  real_sigma=gar1[,1]
  real_data=gar1[,2]
  r.garch <- ugarchspec(mean.model = list(armaOrder = c(0,0),
                                          include.mean = FALSE),variance.model = list(garchOrder = c(1, 1)))  # Fit garch(1,1) 
  fit1 = ugarchfit(data =real_data, spec = r.garch)    
  estimated_par[m,]=fit1@fit$coef
  print(m)
  m = m+1
  if (m == repe+1)
  {
    break
  }
}
estimated_par1=estimated_par

c(mean(estimated_par[,1]),mean(estimated_par[,2]),mean(estimated_par[,3]))

bias_w=mean(estimated_par[,1])-true_par[1]
bias_a=mean(estimated_par[,2])-true_par[2]
bias_b=mean(estimated_par[,3])-true_par[3]
c(bias_w,bias_a,bias_b)

sd_w=sd(estimated_par[,1])/sqrt(1000)
sd_a=sd(estimated_par[,2])/sqrt(1000)
sd_b=sd(estimated_par[,3])/sqrt(1000)
c(sd_w,sd_a,sd_b)


dev.off()
plot(density(estimated_par[,1]))
plot(density(estimated_par[,2]))
plot(density(estimated_par[,3]))



write.table(estimated_par,"Estimation_wcd_4.csv",sep=",",row.names = FALSE)
wcd=read.csv("Estimation_wcd_1.csv")
estimated_par=as.matrix(wcd)

pdf("density plot of w_4.pdf")
plot(density(estimated_par[,1]),main="w")
abline(v=true_par[1],col=2) 
dev.off()

pdf("density plot of a_4.pdf")
plot(density(estimated_par[,2]),main="a")
abline(v=true_par[2],col=2)
dev.off()

pdf("density plot of b_4.pdf")
plot(density(estimated_par[,3]),main="b")
abline(v=true_par[3],col=2)
dev.off()
 

plot(rep(0,100),rep(0,100),type="l",xlim=c(-1,1),ylim=c(0,2),xlab = "all 0 values")
abline(v=0,col=2) 
plot(density(CC[,4]))
abline(v=C[2,2],col=2) 
abline(v=-C[2,2],col=2) 
dev.off()





estimated_par=matrix(0,repe,3)
#xx2=matrix(0,time,2*repe)
#install.packages("matrixcalc")
library(matrixcalc)
#sigma=matrix(0,time,repe)
library(MASS)
library(metRology)
m <- 1
repeat 
{
  #case1
  gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
  real_sigma=gar1[,1]
  real_data=gar1[,2]
  ans1 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                     lower = lower_bound, upper = upper_bound,
                     returns=real_data,action="optimize")
  estimated_params1=colMeans(ans1$par)
  estimated_par[m,]=estimated_params1
  print(m)
  m = m+1
  if (m == repe+1)
  {
    break
  }
}
estimated_par
colMeans(estimated_par)



#univariate t garch

##simulation
#install.packages("metRology")
rm(list=ls())
#install.packages("MASS")
#install.packages("grDevices")
library(MASS)
library(metRology)
unigarch=function(w,c,d,totaltime,nu)
{
  eps=sig=0
  z0=rt(1,nu)/sqrt(nu/(nu-2))
  sig0=w

  eps0=z0*sig0^(0.5)
  sig[1]=w+c*eps0^2+d*sig0
  eps[1]=sig[1]^(0.5)*rt(1,nu)/sqrt(nu/(nu-2))
  
  for (i in (2:totaltime)) 
  {
    sig[i]=w+c*eps[i-1]^2+d*sig[i-1]
    eps[i]=sig[i]^(0.5)*rt(1,nu)/sqrt(nu/(nu-2))
    #eps[i]=sig[i]^(0.5)*rt(1,nu)
  }
  sigdata=sig
  #plot.ts(sigdata)
  epsdata=eps
  #plot.ts(epsdata)
  output=cbind(sigdata,epsdata)
}
gar1=unigarch(totaltime=1200,
              w=0.04^2,c=0.254^2,d=0.941^2,nu=5)
gar1=unigarch(totaltime=12000,
              w=0.003^2,c=0.332,d=0.864^2,nu=5)

#head(gar1)   #        sigdata(volatility)     epsdata(data)
totaltime=1200
burnin=200
garch1=gar1[((burnin+1):totaltime),]
plot.ts(garch1)
summary(garch1)
mean(garch1[,2]) #uncorrelated eta
mean(garch1[,1])
var(garch1[,2]) #uncorrelated eta
var(garch1[,1])

##########estimation
############################################
##########estimation own code###############
############################################
sim.tagarch=garch1[,2]  #t-garch data
sim.vol=garch1[,1]
#sim.data2=sim.copulagarch[,2]
#sim.data3=sim.copulagarch[,3]
#plot(density(sim.vol))
#plot(density(sim.tagarch))
plot.ts(sim.vol)
plot.ts(sim.tagarch)

########garch estimation
garch_likelihood_constrained <- function(theta, tdata) {
  omega <- pmax(pmin(theta[1],Inf), 0)
  #pmax(pmin(x, upper_bound), lower_bound)
  beta <- pmax(pmin(theta[3], 1), 0)
  #alpha <- pmax(pmin(theta[2], pmin(1-theta[3], 1)), 0)
  #alpha <- pmax(pmin(theta[2], 1), 0)
  alpha <- pmax(pmin(theta[2], 1-theta[3]), 0)
  su=theta[3]+theta[2]
  su <- pmax(pmin(su, 1), 0)
  
  nu=theta[4]
  n=length(tdata)
  sigma2 <- numeric(n)
  sigma2[1] <-var(tdata)
  for (t in 2:n) {
    sigma2[t] <- omega+alpha*tdata[t-1]^2+beta*sigma2[t-1]
  }
  #omega=0.00003
  #alpha=0.1
  # beta=0.5
  #plot.ts(sigma2)
  #nu=3
  
  l1=n*log(gamma((nu+1)/2))
  l2=-n*log(gamma(nu/2))
  l3=-0.5*n*log(pi*(nu-2))
  l4=-0.5*sum(log(sigma2))
  l5=-(nu+1)/2*sum(log(1+tdata^2/(sigma2*(nu-2))))
  nll=l1+l2+l3+l4+l5
  list(-nll)
}


#returns <- returns[-1] 
initial_guess <- c(0.001, 0.001, 0.001,8)  
lower_bound <- c(0.001, 0.001, 0.001,3)          
upper_bound <- c(1,1,1,Inf)  # 参数上限
optim_result1 <- optim(initial_guess,garch_likelihood_constrained, tdata=sim.tagarch, method = "L-BFGS-B", lower = lower_bound, upper = upper_bound,hessian=TRUE)

estimated_params1 <- optim_result1$par  # 估计的参数值
estimated_params1


# chapter 2
data=read.csv(file="oil.csv")
oil=data.frame(data)
head(oil)
WTI=oil[,2]
Brent=oil[,3]
summary(WTI)
length(WTI)
summary(Brent)

#install.packages("moments")
#install.packages("tseries")
library(moments)
library(tseries)
skewness_value <- skewness(WTI)
kurtosis_value <- kurtosis(WTI)
jb_test <- jarque.bera.test(WTI)
jb_statistic <- jb_test$statistic
jb_p_value <- jb_test$p.value

skewness_value <- skewness(Brent)
kurtosis_value <- kurtosis(Brent)
jb_test <- jarque.bera.test(Brent)
jb_statistic <- jb_test$statistic
jb_p_value <- jb_test$p.value

adf_test <- adf.test(WTI, alternative = "stationary")
adf_test <- adf.test(Brent, alternative = "stationary")



par(mfrow=c(2,1))
day=as.Date(oil$Date)
plot(day,WTI,xaxt="n",type="l",
     ylab="WTI",xlab="time")
plot(day,Brent,xaxt="n",type="l",
     ylab="Brent",xlab="time")
axis.Date(1, at = seq(day[1], day[length(day)], by = "4 years"),
          format = "%d-%m-%Y", las = 2)



library(forecast)
auto.arima(WTI)
auto.arima(Brent)


####residuals plot
fit1=arima(WTI,order=c(0,0,0))
fit2=arima(Brent,order=c(1,0,0))

dat_arma<-cbind(residuals(fit1),residuals(fit2))
mean(WTI)
sum(WTI)
var(dat_arma)
cor(dat_arma)
m <- apply(dat_arma, 2, mean)
v <- apply(dat_arma, 2, var)
#dat_arma_std <- t((t(dat_arma)-m)/sqrt(v))
par(mfrow=c(2,1))
plot(day[1:length(day)],dat_arma[,1],xaxt="n",type="l",
     ylab="WTI residuals",xlab="time")
plot(day[1:length(day)],dat_arma[,2],xaxt="n",type="l",
     ylab="Brent residuals",xlab="time")
axis.Date(1, at = seq(day[1], day[length(day)], by = "4 years"),
          format = "%d-%m-%Y", las = 2)


summary(dat_arma[,1])
summary(dat_arma[,2])

#install.packages("moments")
#install.packages("tseries")

skewness_value <- skewness(dat_arma[,1])
kurtosis_value <- kurtosis(dat_arma[,1])
jb_test <- jarque.bera.test(dat_arma[,1])


skewness_value <- skewness(dat_arma[,2])
kurtosis_value <- kurtosis(dat_arma[,2])
jb_test <- jarque.bera.test(dat_arma[,2])


#acf plots
acf(dat_arma,lag.max = 10)
squ.residual=dat_arma^2
acf(squ.residual,lag.max = 10)


#acf plots standerdized
acf(dat_arma_std,lag.max = 10)
squ.residual=dat_arma_std^2
acf(squ.residual,lag.max = 10)

#ARCH effect
install.packages("aTSA")
library(aTSA)
mod <- arima(WTI,order = c(0,0,0))
arch.test(mod)
mod <- arima(Brent,order = c(1,0,0))
arch.test(mod)


#GARCH estimation
#########update
garch_likelihood_constrained <- function(theta, returns) {
  omega <- theta[1]
  alpha <- theta[2]
  beta <- theta[3]
  # Check if parameters are within acceptable range
  if (omega > 0 || alpha > 0 || beta > 0 || 0< alpha + beta|| alpha + beta < 1) {
    T <- length(returns)
    sigma2 <- numeric(T)
    sigma2[1] <- var(returns)
    for (t in 2:T) {
      sigma2[t] <- omega + alpha * returns[t-1]^2 + beta * sigma2[t-1]
      if (sigma2[t] <= 0) {
        return(.Machine$double.xmax)
      }
    }
    log_likelihood <- -0.5 * (T * log(2 * pi) + sum(log(sigma2)) + sum(returns^2 / sigma2))
  }
  return(-log_likelihood) # Negative because 'optim' minimizes
}



summary(dat_arma[,1])
summary(dat_arma[,2])

#check (not good)
library(rugarch)
r.garch <- ugarchspec(mean.model = list(armaOrder = c(0,0),
                                        include.mean = FALSE),variance.model = list(garchOrder = c(1, 1)))  # Fit garch(1,1) 
fit1 = ugarchfit(data = dat_arma[,2], spec = r.garch)    
fit1@fit$coef

#install.packages("BB")
library(BB)
pmat <- matrix(runif(3,0,1), 1, 3)  # 5 starting values each of length 3 
lower_bound <- c(1e-6, 1e-4, 1e-4)     
upper_bound <- c(1, 1-1e-4, 1-1e-4)   
ans1 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                   lower = lower_bound, upper = upper_bound,
                   returns=dat_arma[,1],action="optimize")
ans1$par
estimated_params1=colMeans(ans1$par)
estimated_params1

ans2 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                   lower = lower_bound, upper = upper_bound,
                   returns=dat_arma[,2],action="optimize")
ans2$par
estimated_params2=colMeans(ans2$par)
estimated_params2




