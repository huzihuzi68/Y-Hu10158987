# Chapter 2
################################################
#############GARCH(1,1) estimation #############
################################################

#case 1
#gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
#true_par=c(w=0.04^2,c=0.254^2,d=0.941^2)
#> true_par
#w        c        d 
#0.001600 0.064516 0.885481 


#case2
#gar1=unigarch(totaltime=1200,burnin=200,w=0.03^2,c=0.332^2,d=0.864^2)
#true_par=c(w=0.03^2,c=0.332^2,d=0.864^2)
#> true_par
#w        c        d 
#0.000900 0.110224 0.746496 


rm(list=ls())
#install.packages("MASS")
#install.packages("grDevices")
library(MASS)
library(metRology)
unigarch=function(w,c,d,totaltime,burnin)
{
  eps=sig=0
  sig0=w/(1-c-d)
  z0=sig0^(0.5) * rnorm(1)
  eps0=z0*sig0^(0.5)
  sig[1]=w+c*eps0^2+d*sig0
  eps[1]=sig[1]^(0.5)*rnorm(1)
  for(i in 2:totaltime)  # Generate GARCH(1,1) process
  {
    sig[i]=w+c*eps[i-1]^2+d*sig[i-1]
    eps[i]=sig[i]^(0.5)*rnorm(1)
  }
  sigdata=sig
  epsdata=eps
  gar=cbind(sigdata,epsdata)
  output=gar[((burnin+1):totaltime),]
}


garch1=gar1
plot.ts(garch1)

plot(density(garch1[,1])) #sigma
plot(density(garch1[,2])) #data
qqnorm(garch1[,2])  #data normal distribution check
qqline(garch1[,2], col = "red")



#########update
garch_likelihood_constrained <- function(theta, returns) {
  omega <- theta[1]
  alpha <- theta[2]
  beta <- theta[3]
  # Check if parameters are within acceptable range
  if (omega > 0 || alpha > 0 || beta > 0 || 0< alpha + beta|| alpha + beta < 1) {
    T <- length(returns)
    sigma2 <- numeric(T)
    sigma2[1] <- var(returns)
    for (t in 2:T) {
      sigma2[t] <- omega + alpha * returns[t-1]^2 + beta * sigma2[t-1]
      if (sigma2[t] <= 0) {
        return(.Machine$double.xmax)
      }
    }
    log_likelihood <- -0.5 * (T * log(2 * pi) + sum(log(sigma2)) + sum(returns^2 / sigma2))
  }
  return(-log_likelihood) # Negative because 'optim' minimizes
}


garch_likelihood_constrained(theta=c(0.01, 0.1, 0.1),returns=garch1[,2])
log_likelihood=381.0842

garch_likelihood_constrained(theta=c(0.01, 0.1, 0.9),returns=garch1[,2])
log_likelihood=5.267867
garch_likelihood_constrained(theta=c(0.001, 0.06 ,0.88),returns=garch1[,2])


# Number of parameters in the model (omega, alpha, beta for GARCH(1,1))
p <- 3 
# Number of observations
n <- length(garch1[,2])
# Calculate AIC
aic <- -2 * log_likelihood + 2 * p
# Calculate BIC
bic <- -2 * log_likelihood + log(n) * p



# different initial values
initial_guess <- c(0.001, 0.06 ,0.88)  # initial assumption
lower_bound <- c(1e-6, 1e-4, 1e-4)      
upper_bound <- c(1, 1-1e-4, 1-1e-4)   
optim_result1 <- optim(initial_guess,garch_likelihood_constrained, returns=garch1[,2], 
                       method = "L-BFGS-B", lower = lower_bound, upper = upper_bound,
                       hessian=TRUE)
estimated_params=optim_result1$par
estimated_params
#case
#[1] 0.003968071 0.085097497 0.791463493
#case2
#[1] 0.004703353 0.127247069 0.126339038

#case 3
#[1] 0.008604938 0.085766343 0.085769991



initial_guess <- c(0.1, 0.01, 0.01)  
lower_bound <- c(1e-6, 1e-4, 1e-4)      
upper_bound <- c(1, 1-1e-4, 1-1e-4)   
optim_result1 <- optim(initial_guess,garch_likelihood_constrained, returns=garch1[,2], 
                       method = "L-BFGS-B", lower = lower_bound, upper = upper_bound,
                       hessian=TRUE)
estimated_params=optim_result1$par
estimated_params

#case1
#[1] 0.004630044 0.092142727 0.766535095
#case2
#[1] 0.0062304212 0.0007174053 0.0007002197




######Function multiStart (better result)
#install.packages("BB")
library(BB)
pmat <- matrix(runif(3,0,1), 1, 3)  # 1 starting values each of length 3 
lower_bound <- c(1e-6, 1e-4, 1e-4)      
upper_bound <- c(1, 1-1e-4, 1-1e-4)   
ans1 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                   lower = lower_bound, upper = upper_bound,
                   returns=garch1[,2],action="optimize")
ans1$par
estimated_params1=colMeans(ans1$par)
estimated_params1
#case 1
#[1] 0.002009957 0.072449240 0.866441530
#case2
#[1] 0.001201921 0.131406865 0.674716149




#check with exist package
library(rugarch)
r.garch <- ugarchspec(mean.model = list(armaOrder = c(0,0),
                                        include.mean = FALSE),variance.model = list(garchOrder = c(1, 1)))  # Fit garch(1,1) 
fit1 = ugarchfit(data = garch1[,2], spec = r.garch)    
fit1@fit$coef
plot.ts(fit1@fit$residuals)



#true-fit
rmse <- sqrt(mean((garch1[,2] - garfit1[,2])^2))
acf(garch1[,2])
pacf(garch1[,2])
Box.test(garch1[,2], type = "Ljung-Box")
plot.ts(garch1[,2] - garfit1[,2])
fit=ans1$par
garfit1=unigarch(totaltime=1200,burnin=200,w=0.001182586,c=0.06098994,d=0.8973598)
plot.ts(garch1[,1] - garfit1[,1],main = "Delta h_t between simulated vs. fitted", ylab = "Difference")


returns=garch1[,2]
# Performance metrics
actual_data <- returns[(length(returns)-n_forecast+1):length(returns)]
predicted_data <- sigma(forecasts)

# Calculate MSE
mse <- mean((garfit1[,2] - garch1[,2])^2)
# Calculate RMSE
rmse <- sqrt(mse)
# Calculate MAE
mae <- mean(abs(garfit1[,2] - garch1[,2]))


# Comparing statistical properties
# (Assuming 'simulated_data' and 'actual_data' are available)
actual_data=garch1[,2]
simulated_data=garfit1[,2]


actual_data=garch1[,1]
simulated_data=garfit1[,1]# Extracting the simulated sigma (volatility)


compare_stats <- function(simulated_data, actual_data) {
    comparison <- data.frame(
      Metric = c("Mean", "Variance", "Skewness", "Kurtosis"),
      Actual = c(mean(actual_data), var(actual_data), 
                 skewness(actual_data), kurtosis(actual_data)),
      Simulated = c(mean(simulated_data), var(simulated_data), 
                    skewness(simulated_data), kurtosis(simulated_data))
    )
    return(comparison)
  }
  stats_comparison <- compare_stats(simulated_data, actual_data)
  print(stats_comparison)
  
# Additionally, plot density of actual vs. simulated data
plot(density(actual_data), col = "blue", xlim = range(-0.8,0.8), ylim =range(0,3),
       main = "Density Plot of Simulated vs. fited Data", 
       xlab = "Returns", ylab = "Density")
lines(density(simulated_data), col = "red")
legend("topright", legend = c("Simulated","Fitted"), col = c("blue", "red"), lty = 1)
  








print(paste("Mean Absolute Error:", mae))
# Residuals analysis
residuals <- residuals(fit)

# ACF plot of residuals to check for autocorrelation
acf(residuals, main="ACF of Residuals")

# Perform Ljung-Box test
Box.test(residuals, type = "Ljung-Box")


# Calculate MAE and RMSE
mae <- mean(abs(forecast_errors))
rmse <- sqrt(mean(forecast_errors^2))

# Print the results
print(paste("MAE:", mae))
print(paste("RMSE:", rmse))

out_sample=garch1[801:900,2]
# Plot the actual versus forecasted volatility
plot(out_sample, type = 'l', col = 'blue', main = 'Actual vs Forecasted Volatility')
lines(volatility_forecast, col = 'red')
legend("topright", legend = c("Actual", "Forecasted"), col = c("blue", "red"), lty = 1)

vola <- volatility(mod1)
hatmu <- coef(mod1)["mu"]
lb.intel <- hatmu - 2*vola
ub.intel <- hatmu + 2*vola
ylim <- range(c(ts.intel, lb.intel, ub.intel))
x.intel <- c(time(ts.intel))
plot(x.intel, c(ts.intel), type="l",
     xlab="年", ylab="对数收益率")
lines(x.intel, c(lb.intel), col="red")
lines(x.intel, c(ub.intel), col="red")









#case 1
#0.002009794 0.072434284 0.866459763 

#case2
#> fit1@fit$coef
#omega      alpha1       beta1 
#0.001187264 0.130904389 0.677656260 

#case4
#7.600748e-05 1.698201e-01 7.388840e-01 


#sampling distribution
repe=500
time=1000
estimated_par=matrix(0,repe,3)
#xx2=matrix(0,time,2*repe)
#install.packages("matrixcalc")
library(matrixcalc)
#sigma=matrix(0,time,repe)
library(MASS)
library(metRology)
m <- 1
repeat 
{
  #case1
  gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
  real_sigma=gar1[,1]
  real_data=gar1[,2]
  r.garch <- ugarchspec(mean.model = list(armaOrder = c(0,0),
                                          include.mean = FALSE),variance.model = list(garchOrder = c(1, 1)))  # Fit garch(1,1) 
  fit1 = ugarchfit(data =real_data, spec = r.garch)    
  estimated_par[m,]=fit1@fit$coef
  print(m)
  m = m+1
  if (m == repe+1)
  {
    break
  }
}
estimated_par1=estimated_par

c(mean(estimated_par[,1]),mean(estimated_par[,2]),mean(estimated_par[,3]))

bias_w=mean(estimated_par[,1])-true_par[1]
bias_a=mean(estimated_par[,2])-true_par[2]
bias_b=mean(estimated_par[,3])-true_par[3]
c(bias_w,bias_a,bias_b)

sd_w=sd(estimated_par[,1])/sqrt(1000)
sd_a=sd(estimated_par[,2])/sqrt(1000)
sd_b=sd(estimated_par[,3])/sqrt(1000)
c(sd_w,sd_a,sd_b)


dev.off()
plot(density(estimated_par[,1]))
plot(density(estimated_par[,2]))
plot(density(estimated_par[,3]))



write.table(estimated_par,"Estimation_wcd_4.csv",sep=",",row.names = FALSE)
wcd=read.csv("Estimation_wcd_1.csv")
estimated_par=as.matrix(wcd)

pdf("density plot of w_4.pdf")
plot(density(estimated_par[,1]),main="w")
abline(v=true_par[1],col=2) 
dev.off()

pdf("density plot of a_4.pdf")
plot(density(estimated_par[,2]),main="a")
abline(v=true_par[2],col=2)
dev.off()

pdf("density plot of b_4.pdf")
plot(density(estimated_par[,3]),main="b")
abline(v=true_par[3],col=2)
dev.off()
 

plot(rep(0,100),rep(0,100),type="l",xlim=c(-1,1),ylim=c(0,2),xlab = "all 0 values")
abline(v=0,col=2) 
plot(density(CC[,4]))
abline(v=C[2,2],col=2) 
abline(v=-C[2,2],col=2) 
dev.off()





estimated_par=matrix(0,repe,3)
#xx2=matrix(0,time,2*repe)
#install.packages("matrixcalc")
library(matrixcalc)
#sigma=matrix(0,time,repe)
library(MASS)
library(metRology)
m <- 1
repeat 
{
  #case1
  gar1=unigarch(totaltime=1200,burnin=200,w=0.04^2,c=0.254^2,d=0.941^2)
  real_sigma=gar1[,1]
  real_data=gar1[,2]
  ans1 <- multiStart(par=pmat, fn=garch_likelihood_constrained,
                     lower = lower_bound, upper = upper_bound,
                     returns=real_data,action="optimize")
  estimated_params1=colMeans(ans1$par)
  estimated_par[m,]=estimated_params1
  print(m)
  m = m+1
  if (m == repe+1)
  {
    break
  }
}
estimated_par


colMeans(estimated_par)





